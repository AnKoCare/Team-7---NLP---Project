{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyvi in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (0.1.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from pyvi) (1.6.0)\n",
      "Requirement already satisfied: sklearn-crfsuite in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from pyvi) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->pyvi) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->pyvi) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->pyvi) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from scikit-learn->pyvi) (3.5.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from sklearn-crfsuite->pyvi) (0.9.11)\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in /Users/trinhquocan/Library/Python/3.9/lib/python/site-packages (from sklearn-crfsuite->pyvi) (4.67.1)\n",
      "Đang load embedding...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gensim.models import KeyedVectors\n",
    "import re, string\n",
    "!pip install pyvi\n",
    "from pyvi import ViTokenizer\n",
    "\n",
    "# 1) LOAD WORD EMBEDDING & TIỀN XỬ LÝ\n",
    "\n",
    "\n",
    "file_embedding = \"cc.vi.300.vec\"\n",
    "print(\"Đang load embedding...\")\n",
    "model_emb = KeyedVectors.load_word2vec_format(file_embedding, binary=False)\n",
    "embedding_dim = model_emb.vector_size\n",
    "\n",
    "def get_vector(token):\n",
    "    # Trả về vector embedding của token\n",
    "    if token in model_emb.key_to_index:\n",
    "        return model_emb[token]\n",
    "    else:\n",
    "        return np.zeros(embedding_dim, dtype=np.float32)\n",
    "\n",
    "def preprocess_vi(sentence):\n",
    "\n",
    "    s = sentence.lower().strip()\n",
    "    # tokenize\n",
    "    s = ViTokenizer.tokenize(s)\n",
    "    tokens = s.split()\n",
    "    return tokens\n",
    "\n",
    "# 2) HÀM SEMANTIC MATCHING & DECOMPOSITION\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    if norm_a < 1e-9 or norm_b < 1e-9:\n",
    "        return 0.0\n",
    "    return float((a @ b)/(norm_a*norm_b))\n",
    "\n",
    "def find_best_match(vec_s, list_vec_t):\n",
    "    # matching: chọn t_j có cos-sim cao nhất\n",
    "    best_sim = -1.0\n",
    "    best_vec = np.zeros_like(vec_s)\n",
    "    for vec_t in list_vec_t:\n",
    "        sim = cosine_sim(vec_s, vec_t)\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_vec = vec_t\n",
    "    return best_vec\n",
    "\n",
    "def linear_decompose(s_i, s_i_hat):\n",
    "    # alpha = cos(s_i, s_i_hat)\n",
    "    alpha = cosine_sim(s_i, s_i_hat)\n",
    "    s_plus = alpha * s_i\n",
    "    s_minus = (1.0 - alpha) * s_i\n",
    "    return s_plus, s_minus\n",
    "\n",
    "# 3) KIẾN TRÚC MẠNG 2-CHANNEL CNN (giống lúc train)\n",
    "\n",
    "class TwoChannelCNN(nn.Module):\n",
    "    def __init__(self, emb_dim=300, num_filters=64, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=2,\n",
    "            out_channels=num_filters,\n",
    "            kernel_size=(kernel_size, kernel_size),\n",
    "            padding=(1,1)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveMaxPool2d((1,1))\n",
    "        self.fc = nn.Linear(num_filters, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (B, 2, seq_len, emb_dim)\n",
    "        feat = self.conv(x) \n",
    "        feat = nn.functional.relu(feat)\n",
    "        pooled = self.pool(feat)\n",
    "        # => (B, num_filters, 1, 1)\n",
    "        flattened = pooled.squeeze(-1).squeeze(-1) # => (B, num_filters)\n",
    "        out = self.fc(flattened)                  # => (B,1)\n",
    "        out = self.sigmoid(out)                   # => (B,1) ∈ [0,1]\n",
    "        return out\n",
    "\n",
    "# 4) HÀM predict_similarity(model, sent1, sent2)\n",
    "#    Thực hiện pipeline: \n",
    "#      - Preprocess -> get embedding\n",
    "#      - matching + decomposition\n",
    "#      - ghép 2 channel -> CNN -> similarity\n",
    "\n",
    "def predict_similarity(model, sentence1, sentence2, max_len=20):\n",
    "    # 1) Preprocess\n",
    "    tokens_s = preprocess_vi(sentence1)\n",
    "    tokens_t = preprocess_vi(sentence2)\n",
    "    \n",
    "    # 2) Embed\n",
    "    vecs_s = [get_vector(w) for w in tokens_s]\n",
    "    vecs_t = [get_vector(w) for w in tokens_t]\n",
    "    \n",
    "    # 3) Matching + Decomposition\n",
    "    s_plus_list = []\n",
    "    s_minus_list = []\n",
    "    for s_i in vecs_s:\n",
    "        s_i_hat = find_best_match(s_i, vecs_t)\n",
    "        s_plus, s_minus = linear_decompose(s_i, s_i_hat)\n",
    "        s_plus_list.append(s_plus)\n",
    "        s_minus_list.append(s_minus)\n",
    "    \n",
    "    # 4) Truncate / pad cho đủ max_len\n",
    "    s_plus_list  = s_plus_list[:max_len]\n",
    "    s_minus_list = s_minus_list[:max_len]\n",
    "    \n",
    "    pad_len = max_len - len(s_plus_list)\n",
    "    s_plus_list  += [np.zeros(embedding_dim, dtype=np.float32)] * pad_len\n",
    "    s_minus_list += [np.zeros(embedding_dim, dtype=np.float32)] * pad_len\n",
    "    \n",
    "    # (seq_len, emb_dim) => stack => (max_len, emb_dim)\n",
    "    plus_array  = np.stack(s_plus_list, axis=0)\n",
    "    minus_array = np.stack(s_minus_list, axis=0)\n",
    "    \n",
    "    # 5) Ghép 2 kênh => shape (1,2,max_len,emb_dim)\n",
    "    sim_tensor = torch.tensor([plus_array], dtype=torch.float)\n",
    "    dis_tensor = torch.tensor([minus_array], dtype=torch.float)\n",
    "    \n",
    "    input_tensor = torch.stack([sim_tensor, dis_tensor], dim=1)\n",
    "    \n",
    "    # 6) Đưa vào model -> ra similarity\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    # output shape (1,1)\n",
    "    sim_score = float(output.item())\n",
    "    return sim_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Khởi tạo dictionary\n",
    "qa_dict = {}\n",
    "\n",
    "with open(\"q&a-2.csv\", \"r\", encoding=\"utf-8\") as file:\n",
    "    reader = csv.reader(file, delimiter=';')\n",
    "    for row in reader:\n",
    "        question, answer = row\n",
    "        if question in qa_dict:\n",
    "            # Nếu câu hỏi đã tồn tại, thêm câu trả lời vào danh sách\n",
    "            qa_dict[question].append(answer)\n",
    "        else:\n",
    "            # Nếu câu hỏi chưa tồn tại, tạo danh sách mới\n",
    "            qa_dict[question] = [answer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Similarity giữa 2 câu: 0.5788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/mk4zz8y5633d57znqmn946740000gn/T/ipykernel_2897/3315487751.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_weights_vi_6.pt\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "    \n",
    "    model = TwoChannelCNN(emb_dim=embedding_dim, num_filters=64, kernel_size=3).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(\"model_weights_vi_6.pt\", map_location=device))\n",
    "\n",
    "    sentA = \"hang động băng được hình thành như thế nào\"\n",
    "    sentB = \"Động cơ hướng tâm của máy bay được chế tạo như thế nào\"\n",
    "    \n",
    "    similarity_value = predict_similarity(model, sentA, sentB)\n",
    "    print(f\"Similarity giữa 2 câu: {similarity_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/mk4zz8y5633d57znqmn946740000gn/T/ipykernel_2897/3779328771.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model_weights_vi_6.pt\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: hang động được hình thành như thế nào\n",
      "\n",
      "Top most similar questions with answers:\n",
      "1. hang động sông băng được hình thành như thế nào? - Similarity: 0.75\n",
      "   Answers:\n",
      "     - Một hang động sông băng chìm một phần trên sông băng Perito Moreno.\n",
      "     - Mặt tiền băng cao khoảng 60 m\n",
      "     - Các khối băng trong hang động sông băng Titlis\n",
      "     - Hang động sông băng là hang động được hình thành bên trong lớp băng của sông băng.\n",
      "     - Hang động sông băng thường được gọi là hang động băng, nhưng thuật ngữ này được sử dụng chính xác để mô tả các hang động nền đá chứa băng quanh năm.\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.7\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    # Load the model\n",
    "    model = TwoChannelCNN(emb_dim=embedding_dim, num_filters=64, kernel_size=3).to(device)\n",
    "    model.load_state_dict(torch.load(\"model_weights_vi_6.pt\", map_location=device))\n",
    "\n",
    "    # Sample input\n",
    "    sentA = input(\"Enter your question: \")\n",
    "\n",
    "    # Compute similarity for each key\n",
    "    similarities = []\n",
    "    for key in qa_dict.keys():\n",
    "        similarity_value = predict_similarity(model, sentA, key)\n",
    "        if similarity_value > threshold:\n",
    "            similarities.append((key, similarity_value))\n",
    "\n",
    "    # Check if similarities list is empty\n",
    "    if len(similarities) == 0:  # Use len(similarities) to check the length of the list\n",
    "        print(\"No questions found in the dataset matching your question!\")\n",
    "    else:\n",
    "        # Sort by similarity value in descending order\n",
    "        top_keys = sorted(similarities, key=lambda x: x[1], reverse=True)[:5]\n",
    "\n",
    "        # Display the top 5 keys with highest similarity along with their answers\n",
    "        print(\"\\nQuestion: \" + sentA)\n",
    "        print(\"\\nTop most similar questions with answers:\")\n",
    "        for i, (key, sim_value) in enumerate(top_keys, start=1):\n",
    "            print(f\"{i}. {key} - Similarity: {sim_value:.2f}\")\n",
    "            print(\"   Answers:\")\n",
    "            for answer in qa_dict[key]:\n",
    "                print(f\"     - {answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
